{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/waihamyee/anaconda/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "'''This script goes along the blog post\n",
    "\"Building powerful image classification models using very little data\"\n",
    "from blog.keras.io.\n",
    "It uses data that can be downloaded at:\n",
    "https://www.kaggle.com/c/dogs-vs-cats/data\n",
    "In our setup, we:\n",
    "- created a data/ folder\n",
    "- created train/ and validation/ subfolders inside data/\n",
    "- created cats/ and dogs/ subfolders inside train/ and validation/\n",
    "- put the cat pictures index 0-999 in data/train/cats\n",
    "- put the cat pictures index 1000-1400 in data/validation/cats\n",
    "- put the dogs pictures index 12500-13499 in data/train/dogs\n",
    "- put the dog pictures index 13500-13900 in data/validation/dogs\n",
    "So that we have 1000 training examples for each class, and 400 validation examples for each class.\n",
    "In summary, this is our directory structure:\n",
    "```\n",
    "data/\n",
    "    train/\n",
    "        dogs/\n",
    "            dog001.jpg\n",
    "            dog002.jpg\n",
    "            ...\n",
    "        cats/\n",
    "            cat001.jpg\n",
    "            cat002.jpg\n",
    "            ...\n",
    "    validation/\n",
    "        dogs/\n",
    "            dog001.jpg\n",
    "            dog002.jpg\n",
    "            ...\n",
    "        cats/\n",
    "            cat001.jpg\n",
    "            cat002.jpg\n",
    "            ...\n",
    "```\n",
    "'''\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "import matplotlib.pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from urllib import urlretrieve\n",
    "import cPickle as pickle\n",
    "import os\n",
    "import gzip\n",
    "import numpy as np\n",
    "import theano\n",
    "import lasagne\n",
    "from lasagne import layers\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from nolearn.lasagne import visualize\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 28, 28\n",
    "\n",
    "train_data_dir = 'classes/train'\n",
    "validation_data_dir = 'classes/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_train_samples = 400\n",
    "nb_validation_samples = 172\n",
    "nb_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(3, img_width, img_height)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 798 images belonging to 2 classes.\n",
      "Found 342 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "518/500 [===============================] - 2s - loss: 0.5413 - acc: 0.7413 - val_loss: 0.5766 - val_acc: 0.7111\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s - loss: 0.5477 - acc: 0.7300 - val_loss: 0.5737 - val_acc: 0.7222\n",
      "Epoch 3/50\n",
      "518/500 [===============================] - 2s - loss: 0.4939 - acc: 0.7645 - val_loss: 0.5111 - val_acc: 0.7889\n",
      "Epoch 4/50\n",
      "518/500 [===============================] - 2s - loss: 0.4979 - acc: 0.7529 - val_loss: 0.5979 - val_acc: 0.6944\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s - loss: 0.4989 - acc: 0.7720 - val_loss: 0.5305 - val_acc: 0.7278\n",
      "Epoch 6/50\n",
      "518/500 [===============================] - 2s - loss: 0.5103 - acc: 0.7375 - val_loss: 0.5970 - val_acc: 0.6889\n",
      "Epoch 7/50\n",
      "518/500 [===============================] - 2s - loss: 0.4518 - acc: 0.7992 - val_loss: 0.5288 - val_acc: 0.7333\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s - loss: 0.4924 - acc: 0.7820 - val_loss: 0.5137 - val_acc: 0.7556\n",
      "Epoch 9/50\n",
      "518/500 [===============================] - 2s - loss: 0.4737 - acc: 0.7819 - val_loss: 0.5547 - val_acc: 0.7253\n",
      "Epoch 10/50\n",
      "518/500 [===============================] - 2s - loss: 0.4878 - acc: 0.7606 - val_loss: 0.5214 - val_acc: 0.7198\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s - loss: 0.4801 - acc: 0.7840 - val_loss: 0.5652 - val_acc: 0.7308\n",
      "Epoch 12/50\n",
      "518/500 [===============================] - 2s - loss: 0.4744 - acc: 0.7683 - val_loss: 0.5344 - val_acc: 0.7802\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s - loss: 0.4513 - acc: 0.7980 - val_loss: 0.5918 - val_acc: 0.7582\n",
      "Epoch 14/50\n",
      "518/500 [===============================] - 2s - loss: 0.4421 - acc: 0.8031 - val_loss: 0.5627 - val_acc: 0.7143\n",
      "Epoch 15/50\n",
      "518/500 [===============================] - 2s - loss: 0.4201 - acc: 0.7857 - val_loss: 0.6316 - val_acc: 0.7000\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s - loss: 0.4504 - acc: 0.7760 - val_loss: 0.5188 - val_acc: 0.7500\n",
      "Epoch 17/50\n",
      "518/500 [===============================] - 2s - loss: 0.4564 - acc: 0.7876 - val_loss: 0.5445 - val_acc: 0.7556\n",
      "Epoch 18/50\n",
      "518/500 [===============================] - 2s - loss: 0.4028 - acc: 0.8050 - val_loss: 0.4993 - val_acc: 0.7667\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s - loss: 0.4375 - acc: 0.8040 - val_loss: 0.4990 - val_acc: 0.7778\n",
      "Epoch 20/50\n",
      "518/500 [===============================] - 2s - loss: 0.4387 - acc: 0.8089 - val_loss: 0.5315 - val_acc: 0.7333\n",
      "Epoch 21/50\n",
      "518/500 [===============================] - 2s - loss: 0.4101 - acc: 0.8282 - val_loss: 0.5956 - val_acc: 0.7111\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s - loss: 0.4371 - acc: 0.7840 - val_loss: 0.5332 - val_acc: 0.7444\n",
      "Epoch 23/50\n",
      "518/500 [===============================] - 2s - loss: 0.4224 - acc: 0.8069 - val_loss: 0.5451 - val_acc: 0.7389\n",
      "Epoch 24/50\n",
      "518/500 [===============================] - 2s - loss: 0.3965 - acc: 0.8301 - val_loss: 0.5326 - val_acc: 0.7278\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s - loss: 0.4162 - acc: 0.8100 - val_loss: 0.5619 - val_acc: 0.6944\n",
      "Epoch 26/50\n",
      "518/500 [===============================] - 2s - loss: 0.4217 - acc: 0.8166 - val_loss: 0.5235 - val_acc: 0.7389\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s - loss: 0.4021 - acc: 0.8140 - val_loss: 0.4786 - val_acc: 0.7556\n",
      "Epoch 28/50\n",
      "518/500 [===============================] - 2s - loss: 0.4199 - acc: 0.8359 - val_loss: 0.4868 - val_acc: 0.8132\n",
      "Epoch 29/50\n",
      "518/500 [===============================] - 2s - loss: 0.4156 - acc: 0.7799 - val_loss: 0.4544 - val_acc: 0.7637\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s - loss: 0.3813 - acc: 0.8260 - val_loss: 0.5143 - val_acc: 0.7692\n",
      "Epoch 31/50\n",
      "518/500 [===============================] - 2s - loss: 0.3890 - acc: 0.8320 - val_loss: 0.5329 - val_acc: 0.7527\n",
      "Epoch 32/50\n",
      "518/500 [===============================] - 2s - loss: 0.3928 - acc: 0.8417 - val_loss: 0.5892 - val_acc: 0.7637\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s - loss: 0.4099 - acc: 0.8000 - val_loss: 0.5112 - val_acc: 0.7556\n",
      "Epoch 34/50\n",
      "518/500 [===============================] - 2s - loss: 0.3642 - acc: 0.8398 - val_loss: 0.6249 - val_acc: 0.6944\n",
      "Epoch 35/50\n",
      "518/500 [===============================] - 2s - loss: 0.3915 - acc: 0.8340 - val_loss: 0.7284 - val_acc: 0.6611\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s - loss: 0.3817 - acc: 0.8160 - val_loss: 0.5767 - val_acc: 0.7556\n",
      "Epoch 37/50\n",
      "518/500 [===============================] - 2s - loss: 0.3943 - acc: 0.8185 - val_loss: 0.5032 - val_acc: 0.7667\n",
      "Epoch 38/50\n",
      "518/500 [===============================] - 2s - loss: 0.3779 - acc: 0.8224 - val_loss: 0.5803 - val_acc: 0.7889\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s - loss: 0.3878 - acc: 0.8300 - val_loss: 0.4837 - val_acc: 0.7722\n",
      "Epoch 40/50\n",
      "518/500 [===============================] - 2s - loss: 0.3684 - acc: 0.8089 - val_loss: 0.5031 - val_acc: 0.7778\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s - loss: 0.3651 - acc: 0.8360 - val_loss: 0.4646 - val_acc: 0.7944\n",
      "Epoch 42/50\n",
      "518/500 [===============================] - 2s - loss: 0.3566 - acc: 0.8340 - val_loss: 0.5484 - val_acc: 0.7444\n",
      "Epoch 43/50\n",
      "518/500 [===============================] - 2s - loss: 0.3814 - acc: 0.8282 - val_loss: 0.4721 - val_acc: 0.8000\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s - loss: 0.3672 - acc: 0.8360 - val_loss: 0.4872 - val_acc: 0.8056\n",
      "Epoch 45/50\n",
      "518/500 [===============================] - 2s - loss: 0.3287 - acc: 0.8649 - val_loss: 0.4974 - val_acc: 0.7857\n",
      "Epoch 46/50\n",
      "518/500 [===============================] - 2s - loss: 0.3577 - acc: 0.8398 - val_loss: 0.4839 - val_acc: 0.8077\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s - loss: 0.3104 - acc: 0.8760 - val_loss: 0.5114 - val_acc: 0.7582\n",
      "Epoch 48/50\n",
      "518/500 [===============================] - 2s - loss: 0.3612 - acc: 0.8340 - val_loss: 0.6571 - val_acc: 0.6703\n",
      "Epoch 49/50\n",
      "518/500 [===============================] - 2s - loss: 0.3791 - acc: 0.8417 - val_loss: 0.5130 - val_acc: 0.7527\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s - loss: 0.3564 - acc: 0.8660 - val_loss: 0.6098 - val_acc: 0.7363\n",
      "Done!!\n"
     ]
    }
   ],
   "source": [
    "# Train the network\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=500,\n",
    "        nb_epoch=50,\n",
    "        validation_data=validation_generator,\n",
    "        nb_val_samples=172)\n",
    "print \"Done!!\"\n",
    "\n",
    "model.save_weights('first_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid dimensions for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-34e7728b7e29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# this is a Numpy array with shape (1, 3, 150, 150)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/waihamyee/anaconda/lib/python2.7/site-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   3020\u001b[0m                         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m                         \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3022\u001b[0;31m                         **kwargs)\n\u001b[0m\u001b[1;32m   3023\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3024\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwashold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/waihamyee/anaconda/lib/python2.7/site-packages/matplotlib/__init__.pyc\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1810\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1811\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1812\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1813\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1814\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/waihamyee/anaconda/lib/python2.7/site-packages/matplotlib/axes/_axes.pyc\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   4945\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   4946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4947\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4948\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4949\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/waihamyee/anaconda/lib/python2.7/site-packages/matplotlib/image.pyc\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    451\u001b[0m         if (self._A.ndim not in (2, 3) or\n\u001b[1;32m    452\u001b[0m                 (self._A.ndim == 3 and self._A.shape[-1] not in (3, 4))):\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid dimensions for image data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_imcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid dimensions for image data"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQkAAAEACAYAAACgZ4OsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1298599d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "img = load_img('classes/validation/nike/669.png')  # this is a PIL image\n",
    "#x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "\n",
    "plt.imshow(x[0][0], cmap=cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "image_list_j = []\n",
    "for filename in glob.glob('classes/traino/jordans/*.jpg'):\n",
    "    im=Image.open(filename)\n",
    "    image_list_j.append(im)\n",
    "\n",
    "jordans_train = map(lambda x: img_to_array(x),image_list_j)\n",
    "jordan_pd = pd.DataFrame()\n",
    "jordan_pd['image'] = jordans_train\n",
    "jordan_pd['brand'] = 'Jordan'\n",
    "\n",
    "image_list_n = []\n",
    "for filename in glob.glob('classes/traino/nikes/*.jpg'):\n",
    "    im=Image.open(filename)\n",
    "    image_list_n.append(im)\n",
    "\n",
    "nikes_train = map(lambda x: img_to_array(x),image_list_n)\n",
    "nikes_train = map(lambda x: x.reshape((1,) + x.shape), nikes_train)\n",
    "nike_pd = pd.DataFrame()\n",
    "nike_pd['image'] = nikes_train\n",
    "nike_pd['brand'] = 'Nike'\n",
    "\n",
    "frames = [jordan_pd, nike_pd]\n",
    "X = pd.concat(frames,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512\n",
      "379\n",
      "1512\n",
      "379\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X['image'], X['brand'], test_size=0.2, random_state=0)\n",
    "\n",
    "print len(X_train)\n",
    "print len(X_test)\n",
    "print len(y_train)\n",
    "print len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [image, brand]\n",
       "Index: []"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[X.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  image   brand\n",
      "0     [[[255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 2...  Jordan\n",
      "1     [[[255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 2...  Jordan\n",
      "2     [[[255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 2...  Jordan\n",
      "3     [[[255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 2...  Jordan\n",
      "4     [[[252.0, 252.0, 252.0, 252.0, 252.0, 252.0, 2...  Jordan\n",
      "5     [[[255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 2...  Jordan\n",
      "6     [[[255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 2...  Jordan\n",
      "7     [[[255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 2...  Jordan\n",
      "8     [[[255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 2...  Jordan\n",
      "9     [[[255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 2...  Jordan\n",
      "10    [[[246.0, 254.0, 255.0, 254.0, 255.0, 255.0, 2...  Jordan\n",
      "11    [[[255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 2...  Jordan\n",
      "12    [[[255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 2...  Jordan\n",
      "13    [[[255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 2...  Jordan\n",
      "14    [[[255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 2...  Jordan\n",
      "15    [[[255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 2...  Jordan\n",
      "16    [[[255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 2...  Jordan\n",
      "17    [[[255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 2...  Jordan\n",
      "18    [[[255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 2...  Jordan\n",
      "19    [[[255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 2...  Jordan\n",
      "20    [[[253.0, 253.0, 253.0, 253.0, 253.0, 253.0, 2...  Jordan\n",
      "21    [[[255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 2...  Jordan\n",
      "22    [[[255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 2...  Jordan\n",
      "23    [[[255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 2...  Jordan\n",
      "24    [[[255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 2...  Jordan\n",
      "25    [[[255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 2...  Jordan\n",
      "26    [[[255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 2...  Jordan\n",
      "27    [[[255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 2...  Jordan\n",
      "28    [[[249.0, 249.0, 249.0, 249.0, 250.0, 250.0, 2...  Jordan\n",
      "29    [[[255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 2...  Jordan\n",
      "...                                                 ...     ...\n",
      "1321  [[[[ 255.  255.  255.  255.  255.  255.  255. ...    Nike\n",
      "1322  [[[[ 255.  255.  255.  255.  255.  255.  255. ...    Nike\n",
      "1323  [[[[ 255.  255.  255.  255.  255.  255.  255. ...    Nike\n",
      "1324  [[[[ 255.  255.  255.  255.  255.  255.  255. ...    Nike\n",
      "1325  [[[[ 255.  255.  255.  255.  255.  255.  255. ...    Nike\n",
      "1326  [[[[ 255.  255.  255.  255.  255.  255.  255. ...    Nike\n",
      "1327  [[[[ 255.  255.  255.  255.  255.  255.  255. ...    Nike\n",
      "1328  [[[[ 255.  255.  255.  255.  255.  255.  255. ...    Nike\n",
      "1329  [[[[ 255.  255.  255.  255.  255.  255.  255. ...    Nike\n",
      "1330  [[[[ 255.  255.  255.  255.  255.  255.  255. ...    Nike\n",
      "1331  [[[[ 254.  254.  254.  254.  254.  254.  254. ...    Nike\n",
      "1332  [[[[ 255.  255.  255.  255.  255.  255.  255. ...    Nike\n",
      "1333  [[[[ 249.  249.  249.  249.  249.  249.  249. ...    Nike\n",
      "1334  [[[[ 255.  255.  255.  255.  255.  255.  255. ...    Nike\n",
      "1335  [[[[ 254.  254.  254.  254.  254.  254.  254. ...    Nike\n",
      "1336  [[[[ 255.  255.  255.  255.  255.  255.  255. ...    Nike\n",
      "1337  [[[[ 249.  249.  250.  250.  250.  250.  251. ...    Nike\n",
      "1338  [[[[ 255.  255.  255.  255.  255.  255.  255. ...    Nike\n",
      "1339  [[[[ 255.  255.  255.  255.  255.  255.  255. ...    Nike\n",
      "1340  [[[[ 255.  255.  255.  255.  255.  255.  255. ...    Nike\n",
      "1341  [[[[ 255.  255.  255.  255.  255.  255.  255. ...    Nike\n",
      "1342  [[[[ 255.  255.  255.  255.  255.  255.  255. ...    Nike\n",
      "1343  [[[[ 255.  255.  255.  255.  255.  255.  255. ...    Nike\n",
      "1344  [[[[ 255.  255.  255.  255.  255.  255.  255. ...    Nike\n",
      "1345  [[[[ 253.  253.  253.  253.  253.  253.  253. ...    Nike\n",
      "1346  [[[[ 253.  253.  253.  253.  253.  253.  253. ...    Nike\n",
      "1347  [[[[ 255.  255.  255.  255.  255.  255.  255. ...    Nike\n",
      "1348  [[[[ 255.  255.  255.  255.  255.  255.  255. ...    Nike\n",
      "1349  [[[[ 255.  255.  255.  255.  255.  255.  255. ...    Nike\n",
      "1350  [[[[ 255.  255.  255.  255.  255.  255.  255. ...    Nike\n",
      "\n",
      "[1891 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 160362 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name      size\n",
      "---  --------  --------\n",
      "  0  input     1x28x28\n",
      "  1  conv2d1   32x24x24\n",
      "  2  maxpool1  32x12x12\n",
      "  3  conv2d2   32x8x8\n",
      "  4  maxpool2  32x4x4\n",
      "  5  dropout1  32x4x4\n",
      "  6  dense     256\n",
      "  7  dropout2  256\n",
      "  8  output    10\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "('Bad input argument to theano function with name \"/Users/waihamyee/anaconda/lib/python2.7/site-packages/nolearn/lasagne/base.py:518\"  at index 0(0-based)', 'setting an array element with a sequence.')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-281-11698f7f918c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m     )\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# Train the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Done!!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/waihamyee/anaconda/lib/python2.7/site-packages/nolearn/lasagne/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, epochs)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/waihamyee/anaconda/lib/python2.7/site-packages/nolearn/lasagne/base.pyc\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(self, X, y, epochs)\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mXb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_iterator_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m                 train_outputs.append(\n\u001b[0;32m--> 602\u001b[0;31m                     self.apply_batch_func(self.train_iter_, Xb, yb))\n\u001b[0m\u001b[1;32m    603\u001b[0m                 \u001b[0mbatch_train_sizes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/waihamyee/anaconda/lib/python2.7/site-packages/nolearn/lasagne/base.pyc\u001b[0m in \u001b[0;36mapply_batch_func\u001b[0;34m(func, Xb, yb)\u001b[0m\n\u001b[1;32m    690\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0myb\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/waihamyee/anaconda/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    784\u001b[0m                         s.storage[0] = s.type.filter(\n\u001b[1;32m    785\u001b[0m                             \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m                             allow_downcast=s.allow_downcast)\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/waihamyee/anaconda/lib/python2.7/site-packages/theano/tensor/type.pyc\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, data, strict, allow_downcast)\u001b[0m\n\u001b[1;32m    147\u001b[0m                     \u001b[0;31m# data has to be converted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                     \u001b[0;31m# Check that this conversion is lossless\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                     \u001b[0mconverted_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_asarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m                     \u001b[0;31m# We use the `values_eq` static function from TensorType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                     \u001b[0;31m# to handle NaN values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/waihamyee/anaconda/lib/python2.7/site-packages/theano/misc/safe_asarray.pyc\u001b[0m in \u001b[0;36m_asarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert into dtype object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Note that dtype comparison must be done by comparing their `num`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# attribute. One cannot assume that two identical data types are pointers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/waihamyee/anaconda/lib/python2.7/site-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \"\"\"\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: ('Bad input argument to theano function with name \"/Users/waihamyee/anaconda/lib/python2.7/site-packages/nolearn/lasagne/base.py:518\"  at index 0(0-based)', 'setting an array element with a sequence.')"
     ]
    }
   ],
   "source": [
    "net1 = NeuralNet(\n",
    "    layers=[('input', layers.InputLayer),\n",
    "            ('conv2d1', layers.Conv2DLayer),\n",
    "            ('maxpool1', layers.MaxPool2DLayer),\n",
    "            ('conv2d2', layers.Conv2DLayer),\n",
    "            ('maxpool2', layers.MaxPool2DLayer),\n",
    "            ('dropout1', layers.DropoutLayer),\n",
    "            ('dense', layers.DenseLayer),\n",
    "            ('dropout2', layers.DropoutLayer),\n",
    "            ('output', layers.DenseLayer),\n",
    "            ],\n",
    "    # input layer\n",
    "    input_shape=(None, 1, 28, 28),\n",
    "    # layer conv2d1\n",
    "    conv2d1_num_filters=32,\n",
    "    conv2d1_filter_size=(5, 5),\n",
    "    conv2d1_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    conv2d1_W=lasagne.init.GlorotUniform(),  \n",
    "    # layer maxpool1\n",
    "    maxpool1_pool_size=(2, 2),    \n",
    "    # layer conv2d2\n",
    "    conv2d2_num_filters=32,\n",
    "    conv2d2_filter_size=(5, 5),\n",
    "    conv2d2_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    # layer maxpool2\n",
    "    maxpool2_pool_size=(2, 2),\n",
    "    # dropout1\n",
    "    dropout1_p=0.5,    \n",
    "    # dense\n",
    "    dense_num_units=256,\n",
    "    dense_nonlinearity=lasagne.nonlinearities.rectify,    \n",
    "    # dropout2\n",
    "    dropout2_p=0.5,    \n",
    "    # output\n",
    "    output_nonlinearity=lasagne.nonlinearities.softmax,\n",
    "    output_num_units=10,\n",
    "    # optimization method params\n",
    "    update=nesterov_momentum,\n",
    "    update_learning_rate=0.01,\n",
    "    update_momentum=0.9,\n",
    "    max_epochs=10,\n",
    "    verbose=1,\n",
    "    )\n",
    "# Train the network\n",
    "nn = net1.fit(X_train, y_train)\n",
    "\n",
    "print \"Done!!\""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
